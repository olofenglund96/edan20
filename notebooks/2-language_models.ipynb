{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #2: Language models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objectives of this assignment are to:\n",
    "* Write a program to find n-gram statistics\n",
    "* Compute the probability of a sentence\n",
    "* Know what a language model is\n",
    "* Write a short report of 1 to 2 pages on the assignment\n",
    "* Optionally read a short article on the importance of corpora\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have written all the missing code and run all the cells, you will submit your notebook to an automatic marking system. Do not erase the content of the cells as we will possibly check your programs manually.\n",
    "The submission instructions are at the bottom of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Each group will have to write Python programs to count unigrams, bigrams, and trigrams in a corpus of approximately one million words and to determine the probability of a sentence.\n",
    "* You can test you regular expression using the regex101.com site\n",
    "* Each student will have to write a short report of one to two pages and comment briefly the results. In your report, you must produce the tabulated results of your analysis as described below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some imports you may need. Add others as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import math\n",
    "import os\n",
    "import regex as re\n",
    "import requests\n",
    "import sys\n",
    "from zipfile import ZipFile\n",
    "from collections import defaultdict\n",
    "from functools import reduce\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting and analyzing a corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve a corpus of novels by Selma Lagerl&ouml;f from this URL:\n",
    "<a href=\"https://github.com/pnugues/ilppp/blob/master/programs/corpus/Selma.txt\">\n",
    "    <tt>https://github.com/pnugues/ilppp/blob/master/programs/corpus/Selma.txt</tt>\n",
    "</a>. The text of these novels was extracted\n",
    "from <a href=\"https://litteraturbanken.se/forfattare/LagerlofS/titlar\">Lagerlöf arkivet</a> at\n",
    "<a href=\"https://litteraturbanken.se/\">Litteraturbanken</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may have to adjust the path\n",
    "corpus = open('./Selma.txt', encoding='utf8').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the <a href=\"https://github.com/pnugues/ilppp/tree/master/programs/ch02/python\">concordance\n",
    "program </a> to print the lines containing a specific word, for instance <i>Nils</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = 'Nils Holgersson'\n",
    "width = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selma Lagerlöf Nils Holgerssons underbara resa genom Sv\n",
      "! Se på Tummetott! Se på Nils Holgersson Tummetott!» Genast vände\n",
      "r,» sade han. »Jag heter Nils Holgersson och är son till en husma\n",
      "lden. »Inte är det värt, Nils Holgersson, att du är ängslig eller\n",
      " i dem. På den tiden, då Nils Holgersson drog omkring med vildgäs\n",
      "ulle allt visa honom vad Nils Holgersson från Västra Vemmenhög va\n",
      "om ägde rum det året, då Nils Holgersson for omkring med vildgäss\n",
      "m vad det kan kosta dem. Nils Holgersson hade inte haft förstånd \n",
      "de det inte mer sägas om Nils Holgersson, att han inte tyckte om \n",
      " Rosenbom?» För där stod Nils Holgersson mitt uppe på Rosenboms n\n",
      " Med ens fingo de syn på Nils Holgersson, och då sköt den store v\n",
      "vila. När vildgässen och Nils Holgersson äntligen hade letat sig \n",
      " slags arbetare. Men vad Nils Holgersson inte såg, det var, att s\n",
      "nde han fråga, och om då Nils Holgersson sade nej, började han ge\n",
      "de lille Mats, och om nu Nils Holgersson också hade tegat, så had\n",
      "åg så försmädlig ut, att Nils Holgersson kastade sig över honom f\n",
      " brodern. Och inte ville Nils Holgersson slåss med en tös, utan h\n",
      "örkar. På den tiden, när Nils Holgersson for omkring med vildgäss\n",
      " ryckte omkull honom. Om Nils Holgersson genast hade ropat på hjä\n",
      "u reda dig på egen hand, Nils Holgersson,» sade han då till sig s\n",
      "r satte Fumle-Drumle ner Nils Holgersson på bottnen av en sandgro\n",
      "mlingarna. – »Jo, jag är Nils Holgersson från Västra Vemmenhög, s\n",
      "rakten. På den tiden, då Nils Holgersson for omkring med vildgäss\n",
      "Jo, det står – Det står: Nils Holgersson fr. V. Vemmenhög.» »Det \n",
      "visan 1 Sveriges karta 2 Nils Holgerssons underbara resa genom Sv\n",
      "admalsvåden 233 ________ Nils Holgerssons underbara resa genom Sv\n",
      "R. Tolv år ungefär innan Nils Holgersson hade börjat resa omkring\n",
      "och leta efter föda, men Nils Holgersson hade på morgonen tappat \n",
      "ill i Närke det året, då Nils Holgersson for fram över landskapet\n",
      "hade flyttat tassen över Nils Holgerssons ansikte, så att den sta\n",
      "29 april. Denna dag fick Nils Holgersson se södra Dalarna. Vildgä\n",
      "rliga sjön. Det året, då Nils Holgersson for med vildgässen genom\n",
      "t skänka upptäckten till Nils Holgersson. Det var ju både det tro\n",
      " som sången varade, stod Nils Holgersson och lyssnade till den, m\n",
      "ova på en vassrugge. Vad Nils Holgersson angår, så var han för hu\n",
      "e svårt för en sådan som Nils Holgersson att finna en farkost. Ha\n",
      "r de hade kommit mittför Nils Holgersson, slogo de sig ner på ett\n",
      " 5 maj. På den tiden, då Nils Holgersson drog genom landet med vi\n",
      "an vara bra lycklig. Att Nils Holgersson, som för ett par timmar \n",
      " afton. Och således hade Nils Holgersson fått se studenterna, när\n",
      "nger under marschen. Men Nils Holgersson hade tyckt, att det inte\n",
      "och glädja så som dessa. Nils Holgersson hade mest sett på studen\n",
      "m, stannade han. »Jag är Nils Holgersson från Västra Vemmenhög,» \n",
      " Ett par år före det, då Nils Holgersson drog omkring med vildgäs\n",
      " detsamma fattade han om Nils Holgersson med sin stora fot, höjde\n",
      "t ingen mer än den lilla Nils Holgersson, som följde henne. Solen\n",
      " voro klädda med is, och Nils Holgersson ville följa henne dit in\n",
      "t Lappland är mitt!» Men Nils Holgersson hade blivit så ängslig, \n",
      " över klippväggarna, och Nils Holgersson kunde förstå, att det va\n",
      " SJUKDOMEN. Det året, då Nils Holgersson for omkring med vildgäss\n",
      "jligt att undgå den. Vad Nils Holgersson beträffar, så hade han h\n",
      "hade hon slagit klorna i Nils Holgerssons skuldra och hackade eft\n",
      "g, att just det året, då Nils Holgersson for omkring med vildgäss\n",
      " lönt att vara bedrövad, Nils Holgersson,» sade solen. »Världen ä\n",
      "åga om han inte kunde ge Nils Holgersson bättre villkor. ’Det öns\n",
      "du vill,’ sade han. ’Med Nils Holgersson blir det ändå så, som ja\n",
      "a haft av honom. Ja, säg Nils Holgersson, att föräldrarna redan h\n",
      "Västergötland. Den lille Nils Holgersson hade krupit upp på en la\n",
      " honom sämre.» Den lille Nils Holgersson hade följt med barnen he\n",
      "e bara störa.» Då tyckte Nils Holgersson, att när ingen annan gjo\n",
      "n färdig att följa det.» Nils Holgersson sprang raskt neråt vägen\n",
      "rott mellan de unga. Vad Nils Holgersson beträffar, så hade han i\n",
      "on gav sig tid att se på Nils Holgersson, innan hon stötte till. \n",
      " ändå alldeles olik. Den Nils Holgersson, som hade farit bort i v\n",
      " tro det. Välkommen hem, Nils Holgersson, välkommen hem! Det här \n",
      "mig här på gården,» sade Nils Holgersson. »Min egen mor tror, att\n",
      "on riktig sjukdom,» sade Nils Holgersson. »Jag får försöka ställa\n",
      "in kniv här på din hov?» Nils Holgersson var nätt och jämnt färdi\n",
      "sslingen, som var så lik Nils Holgersson, att om det inte var han\n",
      "pojken fanns i närheten. Nils Holgersson hörde honom nog, men han\n",
      "ottrar ihop ett tack för Nils Holgersson? Vad skulle det ha blivi\n"
     ]
    }
   ],
   "source": [
    "# spaces match tabs and newlines\n",
    "pattern = re.sub(' ', '\\\\s+', pattern)\n",
    "# Replaces newlines with spaces in the text\n",
    "clean_corpus = re.sub('\\s+', ' ', corpus)\n",
    "concordance = ('(.{{0,{width}}}{pattern}.{{0,{width}}})'\n",
    "               .format(pattern=pattern, width=width))\n",
    "for match in re.finditer(concordance, clean_corpus):\n",
    "    print(match.group(1))\n",
    "# print the string with 0..width characters on either side"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a simple <a href=\"https://github.com/pnugues/ilppp/tree/master/programs/ch05/python\">tokenization\n",
    "program</a> on your corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    words = re.findall('\\p{L}+', text)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Selma',\n",
       " 'Lagerlöf',\n",
       " 'Nils',\n",
       " 'Holgerssons',\n",
       " 'underbara',\n",
       " 'resa',\n",
       " 'genom',\n",
       " 'Sverige',\n",
       " 'Första',\n",
       " 'bandet']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = tokenize(corpus)\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of unique words in the original corpus and when setting all the words in lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44256"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(tokenize(clean_corpus)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lowercased text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41032"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(tokenize(clean_corpus.lower())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmenting a corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will write a program to tokenize your text, insert `<s>` and `</s>` tags to delimit sentences, and set all the words in lowercase letters. In the end, you will only keep the words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a regular expression that matches all the characters that are neither a letter nor a punctuation sign. The punctuations signs will be the followings: `.;:?!`. In your regex, use the same order. For the definition of a letter, use a Unicode regex. You will call the regex string `nonletter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonletter = '[^\\p{L}.;:?!]+'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a `clean()` function that replaces all the characters that are neither a letter nor a punctuation sign with a space. The punctuations signs will be the followings: `.;:?!`.   For the sentence:\n",
    "\n",
    "_En gång hade de på Mårbacka en barnpiga, som hette Back-Kajsa._\n",
    "\n",
    "the result will be:\n",
    "\n",
    "`En gång hade de på Mårbacka en barnpiga som hette Back Kajsa.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(string):\n",
    "    return re.sub(nonletter, ' ', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_para = 'En gång hade de på Mårbacka en barnpiga, som hette Back-Kajsa. \\\n",
    "Hon var nog sina tre alnar lång, hon hade ett stort, grovt ansikte med stränga, mörka drag, \\\n",
    "hennes händer voro hårda och fulla av sprickor, som barnens hår fastnade i, \\\n",
    "när hon kammade dem, och till humöret var hon dyster och sorgbunden.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'En gång hade de på Mårbacka en barnpiga som hette Back Kajsa. Hon var nog sina tre alnar lång hon hade ett stort grovt ansikte med stränga mörka drag hennes händer voro hårda och fulla av sprickor som barnens hår fastnade i när hon kammade dem och till humöret var hon dyster och sorgbunden.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_para = clean(test_para)\n",
    "test_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_para = 'En gång hade de på Mårbacka en barnpiga, som hette Back-Kajsa. \\\n",
    "Hon var nog sina tre alnar lång, hon hade ett stort, grovt ansikte med stränga, mörka drag, \\\n",
    "hennes händer voro hårda och fulla av sprickor, som barnens hår fastnade i, \\\n",
    "när hon kammade dem, och till humöret var hon dyster och sorgbunden.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segmenter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will write a sentence segmenter that will delimit each sentence with `</s>` and `<s>` symbols. For example the sentence:\n",
    "\n",
    "_En gång hade de på Mårbacka en barnpiga, som hette Back-Kajsa._\n",
    "\n",
    "will be bracketed as:\n",
    "\n",
    "`<s> En gång hade de på Mårbacka en barnpiga som hette Back-Kajsa </s>`\n",
    "\n",
    "As algorithm, you will use a simple heuristics to detect the sentence boundaries: A sentence starts with a capital letter and ends with a period-equivalent punctuation sign. You will write a regex to match these boundaries with a regular expression and you will insert `</s>\\n<s>` symbols with a substitution function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Detecting sentence boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a regular expression that matches a punctuation, a sequence of spaces, and an uppercase letter. Call this regex string `sentence_boundaries`. In the regex, you will remember the value of the uppercase letter using a backreference. Use the Unicode regexes for the letters and the spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_boundaries = '[.?!]\\p{Zs}+(?<cap>\\p{Lu})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Replacement markup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a string to replace the matched boundaries with the sentence boundary markup. Remember that a sentence ends with `</s>` and starts with `<s>` and that there is one sentence per line. Hint: The markup is `</s>\\n<s>`. Remember also that the first letter of your sentence is in a regex backreference. Call the regex string `sentence_markup`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_markup = ' </s>\\n<s> \\g<cap>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying the substitution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your regexes to segment your text. Use the string `sentence_boundaries`, `sentence_markup`, and `test_para` as input and `text` as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = re.sub(sentence_boundaries, sentence_markup, test_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En gång hade de på Mårbacka en barnpiga, som hette Back-Kajsa </s>\n",
      "<s> Hon var nog sina tre alnar lång, hon hade ett stort, grovt ansikte med stränga, mörka drag, hennes händer voro hårda och fulla av sprickor, som barnens hår fastnade i, när hon kammade dem, och till humöret var hon dyster och sorgbunden.\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En gång hade de på Mårbacka en barnpiga, som hette Back-Kajsa </s>\n",
      "<s> Hon var nog sina tre alnar lång, hon hade ett stort, grovt ansikte med stränga, mörka drag, hennes händer voro hårda och fulla av sprickor, som barnens hår fastnade i, när hon kammade dem, och till humöret var hon dyster och sorgbunden.\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should look like this:\n",
    "\n",
    "`En gång hade de på Mårbacka en barnpiga, som hette Back-Kajsa </s>\n",
    "<s> Hon var nog sina tre alnar lång, hon hade ett stort, grovt ansikte med stränga, mörka drag, hennes händer voro hårda och fulla av sprickor, som barnens hår fastnade i, när hon kammade dem, och till humöret var hon dyster och sorgbunden.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert markup codes in the beginning and end of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' <s> ' + text + ' </s> '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <s> En gång hade de på Mårbacka en barnpiga, som hette Back-Kajsa </s>\n",
      "<s> Hon var nog sina tre alnar lång, hon hade ett stort, grovt ansikte med stränga, mörka drag, hennes händer voro hårda och fulla av sprickor, som barnens hår fastnade i, när hon kammade dem, och till humöret var hon dyster och sorgbunden. </s> \n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should look like this:\n",
    "\n",
    "`<s> En gång hade de på Mårbacka en barnpiga, som hette Back-Kajsa </s>\n",
    "<s> Hon var nog sina tre alnar lång, hon hade ett stort, grovt ansikte med stränga, mörka drag, hennes händer voro hårda och fulla av sprickor, som barnens hår fastnade i, när hon kammade dem, och till humöret var hon dyster och sorgbunden. </s>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the space duplicates with one space and remove the punctuation signs. For the spaces, use the Unicode regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = re.sub('[.;:?!\\p{Zs}]+', ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <s> En gång hade de på Mårbacka en barnpiga, som hette Back-Kajsa </s>\n",
      "<s> Hon var nog sina tre alnar lång, hon hade ett stort, grovt ansikte med stränga, mörka drag, hennes händer voro hårda och fulla av sprickor, som barnens hår fastnade i, när hon kammade dem, och till humöret var hon dyster och sorgbunden </s> \n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should look like this:\n",
    "    \n",
    "`<s> En gång hade de på Mårbacka en barnpiga, som hette Back-Kajsa </s>\n",
    "<s> Hon var nog sina tre alnar lång, hon hade ett stort, grovt ansikte med stränga, mörka drag, hennes händer voro hårda och fulla av sprickor, som barnens hår fastnade i, när hon kammade dem, och till humöret var hon dyster och sorgbunden </s>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a `segment_sentences(text)` function to gather the code in the Segmenter section and set the text in lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_sentences(text):\n",
    "    sentence_boundaries = '[.;:?!]\\p{Zs}+(?<cap>\\p{Lu})'\n",
    "    sentence_markup = ' </s>\\n<s> \\g<cap>'\n",
    "    \n",
    "    clean_text = re.sub(sentence_boundaries, sentence_markup, text)\n",
    "    clean_text = ' <s> ' + clean_text + ' </s>'\n",
    "    clean_text = re.sub('[.;:?!\\p{Zs}]+', ' ', clean_text)\n",
    "    clean_text = clean_text.lower()\n",
    "    \n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <s> en gång hade de på mårbacka en barnpiga, som hette back-kajsa </s>\n",
      "<s> hon var nog sina tre alnar lång, hon hade ett stort, grovt ansikte med stränga, mörka drag, hennes händer voro hårda och fulla av sprickor, som barnens hår fastnade i, när hon kammade dem, och till humöret var hon dyster och sorgbunden </s>\n"
     ]
    }
   ],
   "source": [
    "print(segment_sentences(test_para))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate roughly the accuracy of your program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lorem = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Massa tincidunt nunc pulvinar sapien. Metus vulputate eu scelerisque felis imperdiet proin fermentum. Porttitor lacus luctus accumsan tortor posuere ac ut consequat semper. Massa enim nec dui nunc mattis. Aenean et tortor at risus viverra adipiscing at in. Sem fringilla ut morbi tincidunt. Orci dapibus ultrices in iaculis nunc sed augue lacus viverra. Donec ac odio tempor orci. Ipsum dolor sit amet consectetur adipiscing elit. Cras semper auctor neque vitae tempus quam pellentesque nec nam. Vitae auctor eu augue ut lectus arcu bibendum at. Augue eget arcu dictum varius duis at consectetur lorem. Sodales ut eu sem integer vitae justo. Vestibulum lorem sed risus ultricies tristique nulla. Senectus et netus et malesuada. Amet purus gravida quis blandit turpis cursus in hac habitasse. Pharetra diam sit amet nisl suscipit adipiscing bibendum est. Metus dictum at tempor commodo ullamcorper a lacus vestibulum sed. Lectus mauris ultrices eros in cursus turpis massa. Quis enim lobortis scelerisque fermentum dui. Ante in nibh mauris cursus mattis. Adipiscing elit ut aliquam purus sit. Suscipit tellus mauris a diam maecenas sed enim ut sem. Arcu felis bibendum ut tristique et. Neque aliquam vestibulum morbi blandit cursus risus at. Sed turpis tincidunt id aliquet risus feugiat in ante. Facilisis volutpat est velit egestas dui id ornare arcu odio. Consectetur a erat nam at lectus. Cum sociis natoque penatibus et magnis dis. Blandit turpis cursus in hac habitasse platea dictumst. Platea dictumst quisque sagittis purus sit amet volutpat consequat mauris. Faucibus vitae aliquet nec ullamcorper sit amet risus nullam eget. Aliquet lectus proin nibh nisl condimentum id venenatis a condimentum. Eget mauris pharetra et ultrices neque ornare aenean euismod elementum. Aliquam malesuada bibendum arcu vitae elementum curabitur. Enim nec dui nunc mattis enim ut tellus. Neque laoreet suspendisse interdum consectetur libero id. Ac placerat vestibulum lectus mauris ultrices eros. Tellus mauris a diam maecenas sed enim ut. Egestas sed tempus urna et pharetra pharetra massa. Arcu dictum varius duis at consectetur lorem. Bibendum est ultricies integer quis auctor. Praesent elementum facilisis leo vel fringilla. Pretium nibh ipsum consequat nisl vel pretium lectus quam. Malesuada bibendum arcu vitae elementum curabitur vitae nunc sed. Eleifend quam adipiscing vitae proin sagittis. Ipsum nunc aliquet bibendum enim facilisis gravida neque. Dignissim convallis aenean et tortor at risus viverra adipiscing. Aenean euismod elementum nisi quis eleifend quam adipiscing. Vitae tortor condimentum lacinia quis. Praesent elementum facilisis leo vel fringilla est ullamcorper eget nulla. Volutpat est velit egestas dui id ornare arcu odio ut. Pretium fusce id velit ut. Nunc sed blandit libero volutpat sed cras ornare arcu. Placerat vestibulum lectus mauris ultrices eros. Tortor vitae purus faucibus ornare suspendisse sed nisi lacus. Turpis nunc eget lorem dolor. Tincidunt lobortis feugiat vivamus at augue eget. Feugiat vivamus at augue eget. Purus gravida quis blandit turpis cursus in hac habitasse platea. Ut porttitor leo a diam sollicitudin tempor. Vitae et leo duis ut diam quam. Non arcu risus quis varius quam. Vulputate ut pharetra sit amet aliquam id diam. Sit amet massa vitae tortor condimentum lacinia quis vel eros. At augue eget arcu dictum varius. Elementum curabitur vitae nunc sed. Sit amet dictum sit amet justo donec enim diam vulputate. Vel pharetra vel turpis nunc eget lorem dolor sed viverra. Elementum eu facilisis sed odio morbi quis commodo odio aenean. Et tortor consequat id porta nibh venenatis cras sed felis. Imperdiet nulla malesuada pellentesque elit eget gravida cum sociis natoque. Commodo viverra maecenas accumsan lacus vel facilisis. Tempor orci eu lobortis elementum nibh tellus. Ut ornare lectus sit amet est placerat in egestas erat. Leo urna molestie at elementum eu facilisis. Viverra tellus in hac habitasse. Facilisis magna etiam tempor orci eu. Amet nulla facilisi morbi tempus iaculis urna id volutpat. Enim blandit volutpat maecenas volutpat blandit aliquam etiam. In hendrerit gravida rutrum quisque. Et magnis dis parturient montes nascetur ridiculus. In fermentum posuere urna nec. Nulla aliquet enim tortor at auctor urna. Diam vulputate ut pharetra sit amet. At varius vel pharetra vel turpis nunc eget lorem. Cursus eget nunc scelerisque viverra mauris in aliquam sem. Risus in hendrerit gravida rutrum quisque non tellus orci ac. Elit ut aliquam purus sit amet luctus venenatis. Blandit volutpat maecenas volutpat blandit aliquam etiam. Nec feugiat nisl pretium fusce id velit ut tortor. Eu tincidunt tortor aliquam nulla facilisi cras fermentum odio eu. Integer enim neque volutpat ac tincidunt. Dictumst quisque sagittis purus sit amet volutpat consequat. Vitae tortor condimentum lacinia quis vel eros. Ullamcorper sit amet risus nullam eget felis eget. Nunc id cursus metus aliquam eleifend mi. Neque gravida in fermentum et sollicitudin ac orci phasellus egestas. Vitae tortor condimentum lacinia quis vel eros donec ac. Vel elit scelerisque mauris pellentesque. Aenean sed adipiscing diam donec adipiscing tristique. Vitae ultricies leo integer malesuada nunc vel risus commodo. At consectetur lorem donec massa sapien faucibus. Porta non pulvinar neque laoreet suspendisse interdum consectetur libero. Sit amet consectetur adipiscing elit. Id consectetur purus ut faucibus pulvinar elementum integer enim neque. Tellus id interdum velit laoreet id donec. Sed nisi lacus sed viverra tellus in hac habitasse. Gravida arcu ac tortor dignissim. Ac turpis egestas maecenas pharetra convallis posuere morbi leo. Adipiscing diam donec adipiscing tristique. Lectus quam id leo in vitae. Elit scelerisque mauris pellentesque pulvinar pellentesque. Est ultricies integer quis auctor. Tellus id interdum velit laoreet id donec. Nullam eget felis eget nunc lobortis mattis aliquam faucibus. Curabitur gravida arcu ac tortor dignissim convallis aenean et tortor. Tincidunt praesent semper feugiat nibh sed pulvinar proin. Bibendum est ultricies integer quis auctor. Cursus eget nunc scelerisque viverra mauris. Sit amet purus gravida quis blandit. Vel eros donec ac odio tempor orci dapibus. Amet justo donec enim diam. Lectus quam id leo in vitae. Suspendisse interdum consectetur libero id faucibus nisl. Neque volutpat ac tincidunt vitae. Eget dolor morbi non arcu risus quis varius quam quisque. Posuere sollicitudin aliquam ultrices sagittis orci a scelerisque purus semper. Gravida dictum fusce ut placerat orci nulla. Lorem sed risus ultricies tristique nulla aliquet enim tortor at. Vulputate odio ut enim blandit. Tempus egestas sed sed risus pretium quam vulputate. Turpis egestas integer eget aliquet nibh praesent. Id semper risus in hendrerit gravida rutrum. Tempus urna et pharetra pharetra massa massa ultricies mi. Urna cursus eget nunc scelerisque viverra mauris in aliquam. Elit scelerisque mauris pellentesque pulvinar pellentesque. Vestibulum mattis ullamcorper velit sed ullamcorper morbi tincidunt ornare. Varius sit amet mattis vulputate enim nulla aliquet. Vel quam elementum pulvinar etiam non quam lacus. Est sit amet facilisis magna etiam tempor. Aliquam vestibulum morbi blandit cursus risus. Euismod nisi porta lorem mollis aliquam ut porttitor. Nunc scelerisque viverra mauris in aliquam. Phasellus vestibulum lorem sed risus ultricies. Feugiat scelerisque varius morbi enim nunc faucibus a pellentesque. Amet aliquam id diam maecenas ultricies mi eget mauris pharetra. Tellus rutrum tellus pellentesque eu tincidunt tortor aliquam nulla facilisi. Sed id semper risus in hendrerit gravida. Placerat vestibulum lectus mauris ultrices. Ultrices sagittis orci a scelerisque purus semper. Dignissim diam quis enim lobortis scelerisque fermentum. Lorem ipsum dolor sit amet consectetur. Odio pellentesque diam volutpat commodo sed. Sed augue lacus viverra vitae congue. Suspendisse faucibus interdum posuere lorem ipsum. Augue interdum velit euismod in pellentesque massa. Diam quis enim lobortis scelerisque. Sit amet consectetur adipiscing elit pellentesque habitant morbi. Accumsan in nisl nisi scelerisque eu. Odio tempor orci dapibus ultrices in iaculis nunc sed augue. At quis risus sed vulputate. Et molestie ac feugiat sed lectus vestibulum mattis ullamcorper velit. Facilisis gravida neque convallis a cras semper. Nulla posuere sollicitudin aliquam ultrices sagittis orci. In nulla posuere sollicitudin aliquam ultrices sagittis. Feugiat in ante metus dictum at tempor commodo ullamcorper. Pulvinar mattis nunc sed blandit libero volutpat. Pellentesque elit ullamcorper dignissim cras tincidunt lobortis. Ullamcorper malesuada proin libero nunc. Vitae proin sagittis nisl rhoncus mattis rhoncus urna neque. Amet purus gravida quis blandit. Blandit massa enim nec dui nunc mattis enim ut tellus. Lorem ipsum dolor sit amet consectetur adipiscing elit ut aliquam. Feugiat scelerisque varius morbi enim nunc. Sagittis id consectetur purus ut faucibus pulvinar. Pretium aenean pharetra magna ac placerat vestibulum lectus mauris ultrices. Mattis vulputate enim nulla aliquet porttitor lacus luctus accumsan. Sit amet consectetur adipiscing elit. Facilisi nullam vehicula ipsum a arcu cursus vitae. Nunc id cursus metus aliquam eleifend. Sed viverra ipsum nunc aliquet bibendum enim. Suspendisse sed nisi lacus sed viverra tellus in hac habitasse. Congue nisi vitae suscipit tellus. Amet nisl suscipit adipiscing bibendum est ultricies integer quis. Ullamcorper morbi tincidunt ornare massa eget egestas purus viverra. Id aliquet risus feugiat in ante metus dictum at tempor. At risus viverra adipiscing at in tellus integer feugiat. Amet cursus sit amet dictum. Consectetur purus ut faucibus pulvinar elementum integer. Donec ultrices tincidunt arcu non sodales. Placerat vestibulum lectus mauris ultrices eros in. Fringilla phasellus faucibus scelerisque eleifend donec pretium vulputate sapien nec. Sit amet nulla facilisi morbi tempus iaculis urna id volutpat. Dictum non consectetur a erat nam at lectus urna duis. Dictum fusce ut placerat orci nulla pellentesque dignissim. Sagittis vitae et leo duis. Porttitor eget dolor morbi non. Ac orci phasellus egestas tellus rutrum tellus. Gravida rutrum quisque non tellus orci ac auctor augue. Amet dictum sit amet justo donec enim diam. Adipiscing tristique risus nec feugiat in. Bibendum est ultricies integer quis auctor elit. Ac orci phasellus egestas tellus rutrum tellus. Id faucibus nisl tincidunt eget nullam non. Adipiscing diam donec adipiscing tristique risus nec feugiat in fermentum. Diam quam nulla porttitor massa id neque aliquam. Id leo in vitae turpis massa sed elementum tempus egestas. Malesuada pellentesque elit eget gravida cum sociis natoque penatibus et. Eget nullam non nisi est sit amet facilisis. Nec feugiat nisl pretium fusce id velit ut tortor. Gravida arcu ac tortor dignissim convallis aenean et tortor at. Duis ultricies lacus sed turpis. Rhoncus aenean vel elit scelerisque mauris pellentesque pulvinar pellentesque habitant. Sit amet venenatis urna cursus eget nunc scelerisque. Tempus egestas sed sed risus pretium quam vulputate dignissim suspendisse. Consectetur lorem donec massa sapien faucibus et molestie ac. Quis risus sed vulputate odio ut enim blandit volutpat maecenas. Neque convallis a cras semper auctor neque. Eget mi proin sed libero. In hac habitasse platea dictumst quisque sagittis purus sit. Eleifend quam adipiscing vitae proin sagittis nisl rhoncus. Tristique senectus et netus et malesuada fames ac turpis. Metus vulputate eu scelerisque felis imperdiet proin fermentum leo vel. Ultrices eros in cursus turpis massa. Sagittis aliquam malesuada bibendum arcu vitae elementum curabitur vitae nunc. Vitae purus faucibus ornare suspendisse sed nisi lacus sed. At erat pellentesque adipiscing commodo elit at imperdiet dui. Dolor sit amet consectetur adipiscing elit. Aliquam sem fringilla ut morbi tincidunt augue interdum. Hendrerit gravida rutrum quisque non. Enim blandit volutpat maecenas volutpat blandit aliquam etiam erat velit. Lacus viverra vitae congue eu. Enim neque volutpat ac tincidunt vitae semper quis lectus. Sit amet consectetur adipiscing elit ut. Massa sapien faucibus et molestie ac feugiat sed. Imperdiet nulla malesuada pellentesque elit eget gravida cum sociis natoque. Curabitur gravida arcu ac tortor dignissim convallis aenean et tortor. Feugiat scelerisque varius morbi enim. Tortor id aliquet lectus proin nibh. Fringilla urna porttitor rhoncus dolor purus non enim praesent elementum. Mattis rhoncus urna neque viverra justo nec ultrices. Volutpat ac tincidunt vitae semper quis lectus nulla. Adipiscing tristique risus nec feugiat in. Nulla pharetra diam sit amet nisl suscipit adipiscing bibendum est. Amet facilisis magna etiam tempor orci. Massa ultricies mi quis hendrerit. Id faucibus nisl tincidunt eget nullam non. Lacinia at quis risus sed vulputate. Quisque non tellus orci ac auctor augue mauris augue neque. Turpis massa sed elementum tempus egestas. Consectetur a erat nam at lectus urna duis convallis. Fusce ut placerat orci nulla pellentesque dignissim enim sit. Sed elementum tempus egestas sed sed risus pretium quam. Pulvinar mattis nunc sed blandit. Vel pharetra vel turpis nunc eget lorem dolor sed. Ac tortor dignissim convallis aenean et tortor at risus viverra. Feugiat pretium nibh ipsum consequat nisl vel. Vitae tortor condimentum lacinia quis vel eros donec ac odio. Gravida in fermentum et sollicitudin ac orci. Pharetra sit amet aliquam id diam maecenas. Scelerisque felis imperdiet proin fermentum leo vel. Id consectetur purus ut faucibus pulvinar elementum integer. Lacus suspendisse faucibus interdum posuere lorem. Condimentum vitae sapien pellentesque habitant morbi tristique. Nibh sed pulvinar proin gravida hendrerit lectus. Arcu non odio euismod lacinia at quis. Non tellus orci ac auctor. Pellentesque id nibh tortor id aliquet lectus proin. Eu sem integer vitae justo eget magna. Aliquam purus sit amet luctus venenatis lectus magna. Felis eget nunc lobortis mattis aliquam faucibus purus in massa. Ultrices dui sapien eget mi proin sed libero enim sed. Habitant morbi tristique senectus et netus et malesuada fames. Nisl rhoncus mattis rhoncus urna neque viverra justo nec ultrices. Velit euismod in pellentesque massa placerat duis. Id neque aliquam vestibulum morbi blandit cursus. Pulvinar etiam non quam lacus suspendisse faucibus interdum. Sed sed risus pretium quam vulputate dignissim suspendisse in est. Feugiat pretium nibh ipsum consequat nisl vel. Iaculis at erat pellentesque adipiscing commodo. Egestas erat imperdiet sed euismod. Dui id ornare arcu odio ut sem nulla pharetra diam. Scelerisque in dictum non consectetur a erat. Id neque aliquam vestibulum morbi. Nunc lobortis mattis aliquam faucibus purus in massa. Cursus sit amet dictum sit. Et malesuada fames ac turpis egestas sed tempus urna. Consectetur adipiscing elit pellentesque habitant morbi tristique senectus. At urna condimentum mattis pellentesque id nibh. Sagittis vitae et leo duis. Vulputate eu scelerisque felis imperdiet proin fermentum leo vel orci. Sollicitudin aliquam ultrices sagittis orci a. Purus semper eget duis at tellus at urna. Id neque aliquam vestibulum morbi blandit cursus risus. Enim facilisis gravida neque convallis a cras semper. Viverra accumsan in nisl nisi scelerisque eu ultrices vitae. Placerat duis ultricies lacus sed. Imperdiet nulla malesuada pellentesque elit eget gravida cum. Lorem sed risus ultricies tristique nulla aliquet enim tortor. Justo nec ultrices dui sapien eget mi proin sed. Integer vitae justo eget magna fermentum iaculis eu non. Elit pellentesque habitant morbi tristique senectus. Lacus suspendisse faucibus interdum posuere. Sociis natoque penatibus et magnis dis parturient montes nascetur ridiculus. Id aliquet risus feugiat in ante metus dictum at. Feugiat sed lectus vestibulum mattis ullamcorper velit sed. Massa vitae tortor condimentum lacinia quis vel eros donec ac. Pretium quam vulputate dignissim suspendisse in est. Mauris commodo quis imperdiet massa tincidunt nunc. Augue ut lectus arcu bibendum. Sit amet mauris commodo quis imperdiet. Risus feugiat in ante metus dictum at tempor. Eu augue ut lectus arcu bibendum at varius. Viverra vitae congue eu consequat. Rhoncus dolor purus non enim. Ut sem viverra aliquet eget sit amet tellus cras adipiscing. Lacus luctus accumsan tortor posuere ac ut consequat semper viverra. Condimentum vitae sapien pellentesque habitant morbi tristique senectus. Massa sed elementum tempus egestas sed. Aliquet risus feugiat in ante metus. Imperdiet proin fermentum leo vel orci porta. Ac ut consequat semper viverra nam libero justo laoreet sit. Tempus imperdiet nulla malesuada pellentesque elit. Erat imperdiet sed euismod nisi porta lorem mollis. Diam sollicitudin tempor id eu nisl nunc mi. Ullamcorper a lacus vestibulum sed arcu non. Risus nec feugiat in fermentum posuere urna. Egestas pretium aenean pharetra magna ac. Dui id ornare arcu odio ut sem. Lacinia at quis risus sed vulputate. Mattis rhoncus urna neque viverra justo nec. In nisl nisi scelerisque eu. Eget magna fermentum iaculis eu non diam phasellus vestibulum. Bibendum neque egestas congue quisque egestas diam in arcu. Vel pharetra vel turpis nunc eget lorem dolor. In metus vulputate eu scelerisque felis imperdiet. Et sollicitudin ac orci phasellus. Consectetur a erat nam at lectus urna duis. Platea dictumst vestibulum rhoncus est pellentesque elit ullamcorper dignissim cras. Tortor vitae purus faucibus ornare suspendisse sed nisi. Ac tincidunt vitae semper quis lectus nulla at. Duis at tellus at urna condimentum. In vitae turpis massa sed elementum tempus egestas sed sed. Facilisi nullam vehicula ipsum a arcu cursus vitae congue mauris. Velit ut tortor pretium viverra suspendisse potenti nullam. Netus et malesuada fames ac turpis egestas sed tempus. Magna eget est lorem ipsum dolor sit amet consectetur. At consectetur lorem donec massa. Sed viverra tellus in hac habitasse platea. Et malesuada fames ac turpis egestas maecenas pharetra. Mollis aliquam ut porttitor leo a diam sollicitudin tempor id. Eu lobortis elementum nibh tellus molestie. Vitae turpis massa sed elementum. Aliquam ut porttitor leo a diam. Placerat orci nulla pellentesque dignissim enim. Felis donec et odio pellentesque diam volutpat. Nisl nisi scelerisque eu ultrices vitae auctor. Ultricies mi eget mauris pharetra et ultrices. Pulvinar elementum integer enim neque. Eu feugiat pretium nibh ipsum consequat nisl vel. Felis eget nunc lobortis mattis aliquam faucibus purus. Turpis nunc eget lorem dolor sed viverra ipsum nunc aliquet. Dignissim enim sit amet venenatis. Ornare massa eget egestas purus viverra. Mattis nunc sed blandit libero volutpat sed cras ornare arcu. Vulputate enim nulla aliquet porttitor lacus luctus. Dignissim convallis aenean et tortor at risus. Consectetur purus ut faucibus pulvinar elementum integer enim neque. Egestas fringilla phasellus faucibus scelerisque eleifend donec. At ultrices mi tempus imperdiet nulla malesuada pellentesque. Est velit egestas dui id ornare arcu odio. Amet tellus cras adipiscing enim eu. Sed augue lacus viverra vitae congue eu consequat. Diam ut venenatis tellus in metus. In tellus integer feugiat scelerisque varius morbi. Ut pharetra sit amet aliquam id diam maecenas ultricies. Id volutpat lacus laoreet non curabitur gravida arcu. Pulvinar mattis nunc sed blandit libero volutpat sed cras ornare. Vestibulum lectus mauris ultrices eros in cursus. Purus in massa tempor nec feugiat nisl pretium fusce. Tellus molestie nunc non blandit. Aliquet enim tortor at auctor. Egestas pretium aenean pharetra magna ac placerat vestibulum lectus mauris. Malesuada pellentesque elit eget gravida cum sociis natoque penatibus. Congue quisque egestas diam in arcu cursus euismod quis viverra. Dictum non consectetur a erat nam at lectus urna. Interdum velit euismod in pellentesque massa placerat duis ultricies lacus. At urna condimentum mattis pellentesque id. Sed tempus urna et pharetra pharetra. Bibendum enim facilisis gravida neque convallis a cras semper auctor. Sed vulputate odio ut enim. Ullamcorper eget nulla facilisi etiam dignissim diam quis enim. Nunc vel risus commodo viverra maecenas accumsan lacus. Commodo viverra maecenas accumsan lacus vel facilisis volutpat. Enim sed faucibus turpis in eu mi bibendum. Vitae congue mauris rhoncus aenean vel elit scelerisque mauris. Ac auctor augue mauris augue neque gravida in. Orci ac auctor augue mauris augue. Morbi blandit cursus risus at ultrices mi. Tortor pretium viverra suspendisse potenti nullam. Lectus quam id leo in. In mollis nunc sed id semper risus. Eget est lorem ipsum dolor sit amet consectetur adipiscing elit. Lacus luctus accumsan tortor posuere. Volutpat blandit aliquam etiam erat velit. Amet luctus venenatis lectus magna fringilla urna porttitor rhoncus. Aliquam eleifend mi in nulla posuere sollicitudin. Semper eget duis at tellus at urna condimentum. Sit amet consectetur adipiscing elit pellentesque habitant morbi tristique senectus. Eget aliquet nibh praesent tristique magna sit amet purus. Sed odio morbi quis commodo odio aenean sed adipiscing. Sit amet nisl suscipit adipiscing bibendum est. Lobortis feugiat vivamus at augue eget arcu dictum varius. Tincidunt praesent semper feugiat nibh sed. Magna etiam tempor orci eu lobortis elementum nibh tellus molestie. Consequat mauris nunc congue nisi vitae suscipit tellus mauris. Hendrerit dolor magna eget est lorem ipsum. Et netus et malesuada fames ac turpis egestas sed. Mi ipsum faucibus vitae aliquet. Natoque penatibus et magnis dis parturient. Varius sit amet mattis vulputate enim nulla. Viverra orci sagittis eu volutpat odio. Risus at ultrices mi tempus imperdiet nulla malesuada. Cursus sit amet dictum sit. Ante in nibh mauris cursus mattis molestie a. Sit amet cursus sit amet dictum sit amet justo donec. Augue mauris augue neque gravida in fermentum et sollicitudin. Feugiat in ante metus dictum at tempor commodo ullamcorper. Diam sollicitudin tempor id eu nisl nunc mi ipsum faucibus. In nibh mauris cursus mattis molestie a iaculis at erat. Egestas erat imperdiet sed euismod nisi porta. Mi quis hendrerit dolor magna eget est lorem ipsum dolor. Sed tempus urna et pharetra. Mus mauris vitae ultricies leo integer malesuada. Ridiculus mus mauris vitae ultricies leo integer malesuada nunc vel. Sed turpis tincidunt id aliquet risus. Enim neque volutpat ac tincidunt. Egestas erat imperdiet sed euismod nisi porta lorem. Ut porttitor leo a diam. Augue mauris augue neque gravida in fermentum. Sit amet nisl suscipit adipiscing. Vitae semper quis lectus nulla at volutpat diam ut. Vitae suscipit tellus mauris a diam maecenas. Ultrices mi tempus imperdiet nulla malesuada pellentesque elit eget gravida. Quis commodo odio aenean sed adipiscing diam. Purus gravida quis blandit turpis cursus in hac habitasse platea. A condimentum vitae sapien pellentesque habitant morbi tristique. Nunc faucibus a pellentesque sit amet. Egestas maecenas pharetra convallis posuere morbi leo urna molestie. Amet justo donec enim diam vulputate ut pharetra. Id diam vel quam elementum pulvinar etiam non quam lacus. Commodo quis imperdiet massa tincidunt nunc pulvinar sapien et ligula. Leo vel fringilla est ullamcorper eget. Egestas pretium aenean pharetra magna. Rhoncus urna neque viverra justo. Ultricies mi eget mauris pharetra et ultrices neque ornare. Pellentesque habitant morbi tristique senectus. Nec sagittis aliquam malesuada bibendum arcu vitae. Quis risus sed vulputate odio ut enim blandit volutpat. Vitae nunc sed velit dignissim sodales. Duis convallis convallis tellus id interdum velit laoreet id. Faucibus ornare suspendisse sed nisi lacus sed viverra tellus in. Felis bibendum ut tristique et egestas quis. Ut etiam sit amet nisl purus in. Diam quam nulla porttitor massa id neque aliquam vestibulum. Cras semper auctor neque vitae tempus. Turpis in eu mi bibendum. Venenatis lectus magna fringilla urna porttitor rhoncus dolor purus. Cras fermentum odio eu feugiat. Sapien et ligula ullamcorper malesuada proin. Lorem sed risus ultricies tristique nulla aliquet. Accumsan tortor posuere ac ut. Vitae semper quis lectus nulla. Amet nulla facilisi morbi tempus iaculis. Ornare lectus sit amet est placerat. Libero justo laoreet sit amet cursus. Magna fermentum iaculis eu non diam phasellus. Ullamcorper malesuada proin libero nunc consequat interdum varius sit amet. Quam nulla porttitor massa id neque. Sed egestas egestas fringilla phasellus faucibus scelerisque eleifend. Quam vulputate dignissim suspendisse in est. Sit amet nisl purus in mollis nunc sed. At in tellus integer feugiat scelerisque varius morbi enim nunc. Malesuada proin libero nunc consequat. Cursus turpis massa tincidunt dui ut ornare. Proin sed libero enim sed. Id ornare arcu odio ut sem. Pellentesque nec nam aliquam sem et tortor consequat id. Bibendum arcu vitae elementum curabitur vitae nunc sed velit. Scelerisque eu ultrices vitae auctor eu augue ut lectus. Rhoncus mattis rhoncus urna neque viverra justo nec. Praesent tristique magna sit amet. Elit duis tristique sollicitudin nibh sit. In tellus integer feugiat scelerisque varius. Mi sit amet mauris commodo. Lectus urna duis convallis convallis. Fames ac turpis egestas sed tempus urna et. Donec ultrices tincidunt arcu non sodales neque sodales ut.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = segment_sentences(lorem)\n",
    "sentences.count(\"<s>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizing the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean and segment the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_corpus = clean(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_corpus = segment_sentences(clean_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> hon hade fått större kärlek av sina föräldrar än någon annan han visste och sådan kärlek måste vändas i välsignelse </s>\n",
      "<s> då prästen sade detta kom alla människor att se bort mot klara gulla och de förundrade sig över vad de såg </s>\n",
      "<s> prästens ord tycktes redan ha gått i uppfyllelse </s>\n",
      "<s> där stod klara fina gulleborg ifrån skrolycka hon som var uppkallad efter själva solen vid sina föräldrars grav och lyste som en förklarad </s>\n",
      "<s> hon var likaså vacker som den söndagen då hon gick till kyrkan i den röda klänningen om inte vackrare </s>\n"
     ]
    }
   ],
   "source": [
    "print(seg_corpus[-557:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ord till Klara Gulla. Hon hade fått större kärlek av sina föräldrar än någon annan han visste, och sådan kärlek måste vändas i välsignelse.\n",
      "\n",
      "Då prästen sade detta, kom alla människor att se bort mot Klara Gulla, och de förundrade sig över vad de såg.\n",
      "\n",
      "Prästens ord tycktes redan ha gått i uppfyllelse. Där stod Klara Fina Gulleborg ifrån Skrolycka, hon, som var uppkallad efter själva solen, vid sina föräldrars grav och lyste som en förklarad.\n",
      "\n",
      "Hon var likaså vacker som den söndagen, då hon gick till kyrkan i den röda klänningen, om inte vackrare.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(corpus[-557:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result should be a normalized text without punctuation signs where all the sentences are delimited with `<s>` and `</s>` tags. The five last lines of the text should look like this:\n",
    "\n",
    "```\n",
    "<s> hon hade fått större kärlek av sina föräldrar än någon annan han visste och sådan kärlek måste vändas i välsignelse </s> \n",
    "<s> då prästen sade detta kom alla människor att se bort mot klara gulla och de förundrade sig över vad de såg </s>\n",
    "<s> prästens ord tycktes redan ha gått i uppfyllelse </s>\n",
    "<s> där stod klara fina gulleborg ifrån skrolycka hon som var uppkallad efter själva solen vid sina föräldrars grav och lyste som en förklarad </s>\n",
    "<s> hon var likaså vacker som den söndagen då hon gick till kyrkan i den röda klänningen om inte vackrare </s>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now create a list of words from your string. You will consider that a space or a carriage return is an item separator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = re.findall('[^[\\p{Z}\\n]+', seg_corpus)\n",
    "#words = seg_corpus.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1041579\n"
     ]
    }
   ],
   "source": [
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5144417"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'hon', 'hade', 'fått', 'större', 'kärlek', 'av', 'sina', 'föräldrar', 'än', 'någon', 'annan', 'han', 'visste', 'och', 'sådan', 'kärlek', 'måste', 'vändas', 'i', 'välsignelse', '</s>', '<s>', 'då', 'prästen', 'sade', 'detta', 'kom', 'alla', 'människor', 'att', 'se', 'bort', 'mot', 'klara', 'gulla', 'och', 'de', 'förundrade', 'sig', 'över', 'vad', 'de', 'såg', '</s>', '<s>', 'prästens', 'ord', 'tycktes', 'redan', 'ha', 'gått', 'i', 'uppfyllelse', '</s>', '<s>', 'där', 'stod', 'klara', 'fina', 'gulleborg', 'ifrån', 'skrolycka', 'hon', 'som', 'var', 'uppkallad', 'efter', 'själva', 'solen', 'vid', 'sina', 'föräldrars', 'grav', 'och', 'lyste', 'som', 'en', 'förklarad', '</s>', '<s>', 'hon', 'var', 'likaså', 'vacker', 'som', 'den', 'söndagen', 'då', 'hon', 'gick', 'till', 'kyrkan', 'i', 'den', 'röda', 'klänningen', 'om', 'inte', 'vackrare', '</s>']\n"
     ]
    }
   ],
   "source": [
    "print(words[-101:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The five last lines of the corpus should like this:\n",
    "\n",
    "`['<s>', 'hon', 'hade', 'fått', 'större', 'kärlek', 'av', 'sina', 'föräldrar', 'än', 'någon', 'annan', 'han', 'visste', 'och', 'sådan', 'kärlek', 'måste', 'vändas', 'i', 'välsignelse', '</s>', '<s>', 'då', 'prästen', 'sade', 'detta', 'kom', 'alla', 'människor', 'att', 'se', 'bort', 'mot', 'klara', 'gulla', 'och', 'de', 'förundrade', 'sig', 'över', 'vad', 'de', 'såg', '</s>', '<s>', 'prästens', 'ord', 'tycktes', 'redan', 'ha', 'gått', 'i', 'uppfyllelse', '</s>', '<s>', 'där', 'stod', 'klara', 'fina', 'gulleborg', 'ifrån', 'skrolycka', 'hon', 'som', 'var', 'uppkallad', 'efter', 'själva', 'solen', 'vid', 'sina', 'föräldrars', 'grav', 'och', 'lyste', 'som', 'en', 'förklarad', '</s>', '<s>', 'hon', 'var', 'likaså', 'vacker', 'som', 'den', 'söndagen', 'då', 'hon', 'gick', 'till', 'kyrkan', 'i', 'den', 'röda', 'klänningen', 'om', 'inte', 'vackrare', '</s>']`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting unigrams and bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and try programs to compute the frequency of unigrams and bigrams of the training set: [<a\n",
    "            href=\"https://github.com/pnugues/ilppp/tree/master/programs/ch05/python\">Program folder</a>]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigrams(words):\n",
    "    frequency = {}\n",
    "    for i in range(len(words)):\n",
    "        if words[i] in frequency:\n",
    "            frequency[words[i]] += 1\n",
    "        else:\n",
    "            frequency[words[i]] = 1\n",
    "    return frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<s>', 59047),\n",
       " ('selma', 52),\n",
       " ('lagerlöf', 270),\n",
       " ('nils', 87),\n",
       " ('holgerssons', 6),\n",
       " ('underbara', 23),\n",
       " ('resa', 317),\n",
       " ('genom', 688),\n",
       " ('sverige', 56),\n",
       " ('</s>', 59047),\n",
       " ('första', 525),\n",
       " ('bandet', 6),\n",
       " ('bokutgåva', 11),\n",
       " ('albert', 15),\n",
       " ('bonniers', 11),\n",
       " ('förlag', 11),\n",
       " ('stockholm', 77),\n",
       " ('den', 11624),\n",
       " ('kristliga', 2),\n",
       " ('dagvisan', 2)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency = unigrams(words)\n",
    "list(frequency.items())[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigrams(words):\n",
    "    bigrams = []\n",
    "    for i in range(len(words) - 1):\n",
    "        bigrams.append((words[i], words[i + 1]))\n",
    "    frequency_bigrams = {}\n",
    "    for i in range(len(words) - 1):\n",
    "        if bigrams[i] in frequency_bigrams:\n",
    "            frequency_bigrams[bigrams[i]] += 1\n",
    "        else:\n",
    "            frequency_bigrams[bigrams[i]] = 1\n",
    "    return frequency_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('<s>', 'selma'), 8),\n",
       " (('selma', 'lagerlöf'), 11),\n",
       " (('lagerlöf', 'nils'), 1),\n",
       " (('nils', 'holgerssons'), 6),\n",
       " (('holgerssons', 'underbara'), 4),\n",
       " (('underbara', 'resa'), 4),\n",
       " (('resa', 'genom'), 6),\n",
       " (('genom', 'sverige'), 5),\n",
       " (('sverige', '</s>'), 17),\n",
       " (('</s>', '<s>'), 59046),\n",
       " (('<s>', 'första'), 11),\n",
       " (('första', 'bandet'), 1),\n",
       " (('bandet', 'bokutgåva'), 2),\n",
       " (('bokutgåva', 'albert'), 11),\n",
       " (('albert', 'bonniers'), 11),\n",
       " (('bonniers', 'förlag'), 11),\n",
       " (('förlag', 'stockholm'), 10),\n",
       " (('stockholm', '</s>'), 24),\n",
       " (('<s>', 'den'), 1375),\n",
       " (('den', 'kristliga'), 2)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_bigrams = bigrams(words)\n",
    "list(frequency_bigrams.items())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320129 1.176979e+24 2.9508055226853015e-07\n"
     ]
    }
   ],
   "source": [
    "print(len(frequency_bigrams.keys()), \"{:e}\".format(len(words)**4), len(frequency_bigrams.keys()) / len(words)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the report, tell what is the possible number of bigrams and their real number? Explain why such a difference. What would be the possible number of 4-grams.\n",
    "\n",
    "Propose a solution to cope with bigrams unseen in the corpus. This topic will be discussed during the lab session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the likelihood of a sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a program to compute a sentence's probability using unigrams. You may find useful the dictionaries that we saw in the mutual information program: [<a href=\"https://github.com/pnugues/ilppp/tree/master/programs/ch05/python\">Program folder</a>]. Your function will return the perplexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your function should print and tabulate the results as in the examples below with the sentence _Det var en gång en katt som hette Nils_. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "=====================================================\n",
    "wi \t C(wi) \t #words \t P(wi)\n",
    "=====================================================\n",
    "det \t 21108 \t 1041631 \t 0.0202643738521607\n",
    "var \t 12090 \t 1041631 \t 0.01160679741674355\n",
    "en \t 13514 \t 1041631 \t 0.01297388422579589\n",
    "gång \t 1332 \t 1041631 \t 0.001278763784871994\n",
    "en \t 13514 \t 1041631 \t 0.01297388422579589\n",
    "katt \t 16 \t 1041631 \t 1.5360525944408337e-05\n",
    "som \t 16288 \t 1041631 \t 0.015637015411407686\n",
    "hette \t 97 \t 1041631 \t 9.312318853797554e-05\n",
    "nils \t 87 \t 1041631 \t 8.352285982272032e-05\n",
    "</s> \t 59047 \t 1041631 \t 0.056687060964967444\n",
    "=====================================================\n",
    "Prob. unigrams:\t 5.361459667285409e-27\n",
    "Geometric mean prob.: 0.0023600885848765307\n",
    "Entropy rate:\t 8.726943273141258\n",
    "Perplexity:\t 423.71290908655254\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_words = len(words)\n",
    "\n",
    "def unigram_lm(freq, swords):\n",
    "    df = pd.DataFrame([], columns={'wi': str, 'C(wi)': int, '#words': int, 'P(wi)': float}).set_index('wi')\n",
    "    wcounts = []\n",
    "    wfreq = []\n",
    "    \n",
    "    for w in swords:\n",
    "        wcounts.append(freq[w])\n",
    "        wfreq.append(freq[w] / tot_words)\n",
    "    \n",
    "    for i, w in enumerate(swords):\n",
    "        df = df.append({'wi': w, 'C(wi)': wcounts[i], '#words': tot_words, 'P(wi)': wfreq[i]}, ignore_index=True)\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['tot_freq'] = 1\n",
    "    \n",
    "    for f in wfreq:\n",
    "        metrics['tot_freq'] *= f\n",
    "    \n",
    "    metrics['geom_mean'] = metrics['tot_freq'] ** (1/len(wfreq))\n",
    "    \n",
    "    metrics['H'] = -math.log(metrics['tot_freq'], 2) / len(wfreq)\n",
    "    metrics['pp'] = 2 ** metrics['H']\n",
    "    \n",
    "    print(df)\n",
    "    print(f\"Prob. unigrams: {metrics['tot_freq']}\")\n",
    "    print(f\"Geometric mean prob.: {metrics['geom_mean']}\")\n",
    "    print(f\"Entropy rate: {metrics['H']}\")\n",
    "    print(f\"Perplexity: {metrics['pp']}\")\n",
    "          \n",
    "    return metrics['pp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['det', 'var', 'en', 'gång', 'en', 'katt', 'som', 'hette', 'nils', '</s>']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'det var en gång en katt som hette nils </s>'\n",
    "sent_words = sentence.split()\n",
    "sent_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C(wi)   #words     P(wi)     wi\n",
      "0  21108  1039623  0.020304    det\n",
      "1  12090  1039623  0.011629    var\n",
      "2  13514  1039623  0.012999     en\n",
      "3   1332  1039623  0.001281   gång\n",
      "4  13514  1039623  0.012999     en\n",
      "5     16  1039623  0.000015   katt\n",
      "6  16288  1039623  0.015667    som\n",
      "7     97  1039623  0.000093  hette\n",
      "8     87  1039623  0.000084   nils\n",
      "9  58069  1039623  0.055856   </s>\n",
      "Prob. unigrams: 5.375386888519094e-27\n",
      "Geometric mean prob.: 0.0023607009389439992\n",
      "Entropy rate: 8.726568996687329\n",
      "Perplexity: 423.60300006799037\n"
     ]
    }
   ],
   "source": [
    "perplexity_unigrams = unigram_lm(frequency, sent_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "423"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity_unigrams = int(perplexity_unigrams)\n",
    "perplexity_unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a program to compute the sentence probability using bigrams. Your function will tabulate and print the results as below. It will return the perplexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "=====================================================\n",
    "wi \t wi+1 \t Ci,i+1 \t C(i) \t P(wi+1|wi)\n",
    "=====================================================\n",
    "<s>\t det \t 5672 \t 59047 \t 0.09605907158704083\n",
    "det \t var \t 3839 \t 21108 \t 0.1818741709304529\n",
    "var \t en \t 712 \t 12090 \t 0.058891645988420185\n",
    "en \t gång \t 706 \t 13514 \t 0.052242119283705785\n",
    "gång \t en \t 20 \t 1332 \t 0.015015015015015015\n",
    "en \t katt \t 6 \t 13514 \t 0.0004439840165754033\n",
    "katt \t som \t 2 \t 16 \t 0.125\n",
    "som \t hette \t 45 \t 16288 \t 0.002762770137524558\n",
    "hette \t nils \t 0 \t 97 \t 0.0 \t *backoff: \t 8.352285982272032e-05\n",
    "nils \t </s> \t 2 \t 87 \t 0.022988505747126436\n",
    "=====================================================\n",
    "Prob. bigrams:\t 2.376007803503683e-19\n",
    "Geometric mean prob.: 0.013727289294133601\n",
    "Entropy rate:\t 6.186809422848149\n",
    "Perplexity:\t 72.84759420254609\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_words = len(words)\n",
    "\n",
    "def bigram_lm(freq, freq_bi, swords):\n",
    "    wcounts = []\n",
    "    wcounts_bi = []\n",
    "    wfreq = []\n",
    "    \n",
    "    for i in range(len(swords) - 1):\n",
    "        w1, w2 = swords[i:i+2]\n",
    "        wcounts.append(freq[w1])\n",
    "        if (w1, w2) in freq_bi:\n",
    "            wfreq.append(freq_bi[(w1, w2)] / freq[w1])\n",
    "            wcounts_bi.append(freq_bi[(w1, w2)])\n",
    "        else:\n",
    "            wfreq.append(freq[w2] / tot_words)\n",
    "            wcounts_bi.append(0)\n",
    "    \n",
    "    print(\"wi\\t wi+1\\t Ci,i+1\\t C(i)\\t P(wi)\")\n",
    "    for i in range(len(swords) - 1):\n",
    "        if (swords[i], swords[i+1]) in freq_bi:\n",
    "            print(f\"{swords[i]}\\t {swords[i+1]}\\t {wcounts_bi[i]}\\t {wcounts[i]}\\t {wfreq[i]}\")\n",
    "        else:\n",
    "            print(f\"{swords[i]}\\t {swords[i+1]}\\t {wcounts_bi[i]}\\t {wcounts[i]}\\t 0\\t *backoff: {wfreq[i]}\")\n",
    "\n",
    "    \n",
    "    metrics = {}\n",
    "    #metrics['tot_freq'] = freq[swords[0]] / tot_words\n",
    "    metrics['tot_freq'] = 1\n",
    "\n",
    "    for i in range(len(wfreq)):\n",
    "        metrics['tot_freq'] *= wfreq[i]\n",
    "    \n",
    "    metrics['geom_mean'] = metrics['tot_freq'] ** (1/len(wfreq))\n",
    "    \n",
    "    metrics['H'] = -math.log(metrics['tot_freq'], 2) / len(wfreq)\n",
    "    metrics['pp'] = 2 ** metrics['H']\n",
    "\n",
    "    print(f\"Prob. bigrams: {metrics['tot_freq']}\")\n",
    "    print(f\"Geometric mean prob.: {metrics['geom_mean']}\")\n",
    "    print(f\"Entropy rate: {metrics['H']}\")\n",
    "    print(f\"Perplexity: {metrics['pp']}\")\n",
    "          \n",
    "    return metrics['pp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wi\t wi+1\t Ci,i+1\t C(i)\t P(wi)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'swords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-52d12cc8ed38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"wi\\t wi+1\\t Ci,i+1\\t C(i)\\t P(wi)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mswords\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mswords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfreq_bi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{swords[i]}\\t {swords[i+1]}\\t {wcounts_bi[i]}\\t {wcounts[i]}\\t {wfreq[i]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'swords' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wi\t wi+1\t Ci,i+1\t C(i)\t P(wi)\n",
      "<s>\t det\t 5568\t 58069\t 0.09588592880883087\n",
      "det\t var\t 3839\t 21108\t 0.1818741709304529\n",
      "var\t en\t 712\t 12090\t 0.058891645988420185\n",
      "en\t gång\t 706\t 13514\t 0.052242119283705785\n",
      "gång\t en\t 20\t 1332\t 0.015015015015015015\n",
      "en\t katt\t 6\t 13514\t 0.0004439840165754033\n",
      "katt\t som\t 2\t 16\t 0.125\n",
      "som\t hette\t 45\t 16288\t 0.002762770137524558\n",
      "hette\t nils\t 0\t 97\t 0\t *backoff: 8.368418166970142e-05\n",
      "nils\t </s>\t 2\t 87\t 0.022988505747126436\n",
      "Prob. bigrams: 2.3763060554228703e-19\n",
      "Geometric mean prob.: 0.013727461598244782\n",
      "Entropy rate: 6.1867913143402475\n",
      "Perplexity: 72.84667983539373\n"
     ]
    }
   ],
   "source": [
    "sentence = '<s> det var en gång en katt som hette nils </s>'\n",
    "sent_words = sentence.split()\n",
    "sent_words\n",
    "perplexity_bigrams = bigram_lm(frequency, frequency_bigrams, sent_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity_bigrams = int(perplexity_bigrams)\n",
    "perplexity_bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to this sentence, _Det var en gång en katt som hette Nils_, write five other sentences that will form your test set and run your programs on them. You will insert them in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wi\t wi+1\t Ci,i+1\t C(i)\t P(wi)\n",
      "<s>\t hej\t 1\t 59047\t 1.6935661422256845e-05\n",
      "hej\t det\t 0\t 3\t 0\t *backoff: 0.020265385534846612\n",
      "det\t var\t 3839\t 21108\t 0.1818741709304529\n",
      "var\t en\t 712\t 12090\t 0.058891645988420185\n",
      "en\t fin\t 11\t 13514\t 0.000813970697054906\n",
      "fin\t dag\t 0\t 55\t 0\t *backoff: 0.0009043961139769524\n",
      "dag\t </s>\t 150\t 942\t 0.1592356687898089\n",
      "Prob. bigrams: 4.309129707332837e-16\n",
      "Geometric mean prob.: 0.00638135338085044\n",
      "Entropy rate: 7.2919218561612285\n",
      "Perplexity: 156.70656995753637\n",
      "wi\t wi+1\t Ci,i+1\t C(i)\t P(wi)\n",
      "<s>\t varför\t 184\t 59047\t 0.0031161617016952597\n",
      "varför\t är\t 7\t 358\t 0.019553072625698324\n",
      "är\t dagen\t 1\t 6290\t 0.0001589825119236884\n",
      "dagen\t så\t 2\t 431\t 0.004640371229698376\n",
      "så\t lång\t 21\t 9149\t 0.0022953328232593728\n",
      "lång\t </s>\t 6\t 340\t 0.01764705882352941\n",
      "Prob. bigrams: 1.820769960172266e-15\n",
      "Geometric mean prob.: 0.0034944259884605727\n",
      "Entropy rate: 8.16072879375764\n",
      "Perplexity: 286.17003287585396\n",
      "wi\t wi+1\t Ci,i+1\t C(i)\t P(wi)\n",
      "<s>\t man\t 280\t 59047\t 0.004741985198231917\n",
      "man\t lever\t 1\t 2322\t 0.0004306632213608958\n",
      "lever\t som\t 0\t 59\t 0\t *backoff: 0.015637796076917832\n",
      "som\t man\t 127\t 16288\t 0.007797151277013753\n",
      "man\t lär\t 0\t 2322\t 0\t *backoff: 7.488630243121262e-05\n",
      "lär\t </s>\t 0\t 78\t 0\t *backoff: 0.056689891021228345\n",
      "Prob. bigrams: 1.0571034592059649e-15\n",
      "Geometric mean prob.: 0.003191681764739082\n",
      "Entropy rate: 8.291467473741154\n",
      "Perplexity: 313.314444769449\n",
      "wi\t wi+1\t Ci,i+1\t C(i)\t P(wi)\n",
      "<s>\t hur\t 238\t 59047\t 0.004030687418497129\n",
      "hur\t kan\t 33\t 1996\t 0.016533066132264528\n",
      "kan\t fåglar\t 0\t 2078\t 0\t *backoff: 6.432541362681083e-05\n",
      "fåglar\t flyga\t 0\t 67\t 0\t *backoff: 8.448711043521423e-05\n",
      "flyga\t </s>\t 9\t 88\t 0.10227272727272728\n",
      "Prob. bigrams: 3.7039524643128606e-14\n",
      "Geometric mean prob.: 0.0020593638310277317\n",
      "Entropy rate: 8.923585548985512\n",
      "Perplexity: 485.58685208186205\n",
      "wi\t wi+1\t Ci,i+1\t C(i)\t P(wi)\n",
      "<s>\t det\t 5672\t 59047\t 0.09605907158704083\n",
      "det\t var\t 3839\t 21108\t 0.1818741709304529\n",
      "var\t en\t 712\t 12090\t 0.058891645988420185\n",
      "en\t fin\t 11\t 13514\t 0.000813970697054906\n",
      "fin\t natt\t 0\t 55\t 0\t *backoff: 0.00024578068490244137\n",
      "natt\t i\t 7\t 256\t 0.02734375\n",
      "i\t juli\t 5\t 16508\t 0.0003028834504482675\n",
      "juli\t </s>\t 2\t 8\t 0.25\n",
      "Prob. bigrams: 4.261801838770797e-16\n",
      "Geometric mean prob.: 0.011986686765586825\n",
      "Entropy rate: 6.3824232505733205\n",
      "Perplexity: 83.42588903473724\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"hej det var en fin dag\", \"varför är dagen så lång\", \"man lever som man lär\", \"hur kan fåglar flyga\", \"det var en fin natt i juli\"]\n",
    "\n",
    "for sentence in sentences:\n",
    "    sent_words = f\"<s> {sentence} </s>\".split()\n",
    "    perplexity_bigrams = bigram_lm(frequency, frequency_bigrams, sent_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online prediction of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now carry out an online prediction of words. You will consider two cases:\n",
    "1. Prediction of the current word a user is typing;\n",
    "2. Prediction of the next word.\n",
    "\n",
    "Ideally, you would write a loop that reads the words and apply the models while typing. As the Jupyter labs are not designed for interactive input and output, we will simplify the experimental settings with constant strings at a given time of the input.  \n",
    "\n",
    "We will assume the user is typing the phrase: _Det var en gång_. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have a more accurate prediction, you will use a trigram counting function. Program it following the model of bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigrams(words):\n",
    "    trigrams = [tuple(words[inx:inx + 3])\n",
    "                for inx in range(len(words) - 2)]\n",
    "    frequencies = {}\n",
    "    for trigram in trigrams:\n",
    "        if trigram in frequencies:\n",
    "            frequencies[trigram] += 1\n",
    "        else:\n",
    "            frequencies[trigram] = 1\n",
    "    return frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_words = len(words)\n",
    "\n",
    "def trigram_lm(freq, freq_bi, freq_tri, swords):\n",
    "    wcounts = []\n",
    "    wcounts_tri = []\n",
    "    wfreq = []\n",
    "    \n",
    "    for i in range(len(swords) - 1):\n",
    "        w1, w2, w3 = swords[i:i+3]\n",
    "        wcounts.append(freq[w1])\n",
    "        \n",
    "        if (w1, w2) in freq_bi:\n",
    "            wfreq.append(freq_bi[(w1, w2)] / freq[w1])\n",
    "            wcounts_bi.append(freq_bi[(w1, w2)])\n",
    "        else:\n",
    "            wfreq.append(freq[w2] / tot_words)\n",
    "            wcounts_bi.append(0)\n",
    "    \n",
    "    print(\"wi\\t wi+1\\t Ci,i+1\\t C(i)\\t P(wi)\")\n",
    "    for i in range(len(swords) - 1):\n",
    "        if (swords[i], swords[i+1]) in freq_bi:\n",
    "            print(f\"{swords[i]}\\t {swords[i+1]}\\t {wcounts_bi[i]}\\t {wcounts[i]}\\t {wfreq[i]}\")\n",
    "        else:\n",
    "            print(f\"{swords[i]}\\t {swords[i+1]}\\t {wcounts_bi[i]}\\t {wcounts[i]}\\t 0\\t *backoff: {wfreq[i]}\")\n",
    "    \n",
    "    metrics = {}\n",
    "    #metrics['tot_freq'] = freq[swords[0]] / tot_words\n",
    "    metrics['tot_freq'] = 1\n",
    "\n",
    "    for i in range(len(wfreq)):\n",
    "        metrics['tot_freq'] *= wfreq[i]\n",
    "    \n",
    "    metrics['geom_mean'] = metrics['tot_freq'] ** (1/len(wfreq))\n",
    "    \n",
    "    metrics['H'] = -math.log(metrics['tot_freq'], 2) / len(wfreq)\n",
    "    metrics['pp'] = 2 ** metrics['H']\n",
    "\n",
    "    print(f\"Prob. bigrams: {metrics['tot_freq']}\")\n",
    "    print(f\"Geometric mean prob.: {metrics['geom_mean']}\")\n",
    "    print(f\"Entropy rate: {metrics['H']}\")\n",
    "    print(f\"Perplexity: {metrics['pp']}\")\n",
    "          \n",
    "    return metrics['pp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_trigrams = trigrams(words)\n",
    "frequency_trigrams[('det', 'var', 'en')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user starts typing _Det var en gång_. After the 2nd character, your program tries to help the user with suggested words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_text = 'De'.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a program to rank the five first candidates at this point. Assign these predictions in a list that you will call `current_word_predictions_1`. Note that you are starting a sentence and you can then use the bigram frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "cand_nbr = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = []\n",
    "for k, v in frequency_bigrams.items():\n",
    "    if k[0].startswith(starting_text):\n",
    "        candidates.append((k[0], v))\n",
    "\n",
    "merged_candidates = defaultdict(int)\n",
    "for k, f in candidates:\n",
    "    merged_candidates[k] += f\n",
    "\n",
    "sorted_candidates = {k: v for k, v in sorted(merged_candidates.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "current_word_predictions_1 = []\n",
    "for i, k in enumerate(sorted_candidates.keys()):\n",
    "    if i == cand_nbr:\n",
    "        break\n",
    "    current_word_predictions_1.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['det', 'de', 'den', 'dem', 'detta']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_word_predictions_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now suppose that the user has typed: _Det var en_. After detecting a space, your program starts predicting a next possible word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_text = \"Det var en \".lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize this text and return a list of tokens. Call it `tokens`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenize(current_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['det', 'var', 'en']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a program to propose the five next possible words ranked by frequency using a trigram model. Assign these predictions to a variable that you will call `next_word_predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = []\n",
    "for k, v in frequency_trigrams.items():\n",
    "    if list(k[0:2]) == tokens[1:]:\n",
    "        candidates.append((k[2], v))\n",
    "    \n",
    "    if list(k[1]) == tokens[-1]:\n",
    "        candidates.append((k[1], v))\n",
    "        \n",
    "        \n",
    "merged_candidates = defaultdict(int)\n",
    "for k, f in candidates:\n",
    "    merged_candidates[k] += f\n",
    "    \n",
    "sorted_candidates = {k: v for k, v in sorted(merged_candidates.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "next_word_predictions = []\n",
    "for i, k in enumerate(sorted_candidates.keys()):\n",
    "    if i == cand_nbr:\n",
    "        break\n",
    "    next_word_predictions.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stor', 'liten', 'gammal', 'god', 'sådan']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_word_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us suppose that the user has typed _Det var en g_, rank the five possible candidates. Assign these predictions in a list that you will call `current_word_predictions_2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_text = \"Det var en g\".lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wi\t wi+1\t Ci,i+1\t C(i)\t P(wi)\n",
      "det\t var\t 3839\t 21108\t 0.1818741709304529\n",
      "var\t en\t 712\t 12090\t 0.058891645988420185\n",
      "en\t gång\t 706\t 13514\t 0.052242119283705785\n",
      "Prob. bigrams: 0.0005595585110215183\n",
      "Geometric mean prob.: 0.08240403956289206\n",
      "Entropy rate: 3.6011411276756427\n",
      "Perplexity: 12.135327409972229\n",
      "wi\t wi+1\t Ci,i+1\t C(i)\t P(wi)\n",
      "det\t var\t 3839\t 21108\t 0.1818741709304529\n",
      "var\t en\t 712\t 12090\t 0.058891645988420185\n",
      "en\t grov\t 5\t 13514\t 0.00036998668047950276\n",
      "Prob. bigrams: 3.962878973240216e-06\n",
      "Geometric mean prob.: 0.015824752865310397\n",
      "Entropy rate: 5.981673220470249\n",
      "Perplexity: 63.192140092886426\n",
      "wi\t wi+1\t Ci,i+1\t C(i)\t P(wi)\n",
      "det\t var\t 3839\t 21108\t 0.1818741709304529\n",
      "var\t en\t 712\t 12090\t 0.058891645988420185\n",
      "en\t gås\t 11\t 13514\t 0.000813970697054906\n",
      "Prob. bigrams: 8.718333741128473e-06\n",
      "Geometric mean prob.: 0.020581538225159682\n",
      "Entropy rate: 5.602505379220271\n",
      "Perplexity: 48.58723332824373\n",
      "wi\t wi+1\t Ci,i+1\t C(i)\t P(wi)\n",
      "det\t var\t 3839\t 21108\t 0.1818741709304529\n",
      "var\t en\t 712\t 12090\t 0.058891645988420185\n",
      "en\t gammal\t 208\t 13514\t 0.015391445907947315\n",
      "Prob. bigrams: 0.00016485576528679297\n",
      "Geometric mean prob.: 0.054832079057149465\n",
      "Entropy rate: 4.188836012719006\n",
      "Perplexity: 18.237499237585666\n",
      "wi\t wi+1\t Ci,i+1\t C(i)\t P(wi)\n",
      "det\t var\t 3839\t 21108\t 0.1818741709304529\n",
      "var\t en\t 712\t 12090\t 0.058891645988420185\n",
      "en\t god\t 152\t 13514\t 0.011247595086576884\n",
      "Prob. bigrams: 0.00012047152078650255\n",
      "Geometric mean prob.: 0.049388760957109944\n",
      "Entropy rate: 4.339673414284841\n",
      "Perplexity: 20.247521513415126\n",
      "wi\t wi+1\t Ci,i+1\t C(i)\t P(wi)\n",
      "det\t var\t 3839\t 21108\t 0.1818741709304529\n",
      "var\t en\t 712\t 12090\t 0.058891645988420185\n",
      "en\t gruvarbetare\t 1\t 13514\t 7.399733609590054e-05\n",
      "Prob. bigrams: 7.92575794648043e-07\n",
      "Geometric mean prob.: 0.009254371616200496\n",
      "Entropy rate: 6.75564925209937\n",
      "Perplexity: 108.05703957785992\n",
      "wi\t wi+1\t Ci,i+1\t C(i)\t P(wi)\n",
      "det\t var\t 3839\t 21108\t 0.1818741709304529\n",
      "var\t en\t 712\t 12090\t 0.058891645988420185\n",
      "en\t gruva\t 2\t 13514\t 0.0001479946721918011\n",
      "Prob. bigrams: 1.585151589296086e-06\n",
      "Geometric mean prob.: 0.011659777602800642\n",
      "Entropy rate: 6.422315918766036\n",
      "Perplexity: 85.76492914923207\n",
      "wi\t wi+1\t Ci,i+1\t C(i)\t P(wi)\n",
      "det\t var\t 3839\t 21108\t 0.1818741709304529\n",
      "var\t en\t 712\t 12090\t 0.058891645988420185\n",
      "en\t glad\t 12\t 13514\t 0.0008879680331508066\n",
      "Prob. bigrams: 9.510909535776517e-06\n",
      "Geometric mean prob.: 0.021187221989892008\n",
      "Entropy rate: 5.560661751858984\n",
      "Perplexity: 47.19825942622773\n",
      "wi\t wi+1\t Ci,i+1\t C(i)\t P(wi)\n",
      "det\t var\t 3839\t 21108\t 0.1818741709304529\n",
      "var\t en\t 712\t 12090\t 0.058891645988420185\n",
      "en\t gammaldags\t 3\t 13514\t 0.00022199200828770165\n",
      "Prob. bigrams: 2.3777273839441292e-06\n",
      "Geometric mean prob.: 0.013347113486930242\n",
      "Entropy rate: 6.2273284185256506\n",
      "Perplexity: 74.9225666642619\n",
      "wi\t wi+1\t Ci,i+1\t C(i)\t P(wi)\n",
      "det\t var\t 3839\t 21108\t 0.1818741709304529\n",
      "var\t en\t 712\t 12090\t 0.058891645988420185\n",
      "en\t graf\t 7\t 13514\t 0.0005179813526713039\n",
      "Prob. bigrams: 5.548030562536302e-06\n",
      "Geometric mean prob.: 0.01770297604159364\n",
      "Entropy rate: 5.819864278080169\n",
      "Perplexity: 56.48767741934873\n",
      "wi\t wi+1\t Ci,i+1\t C(i)\t P(wi)\n",
      "det\t var\t 3839\t 21108\t 0.1818741709304529\n",
      "var\t en\t 712\t 12090\t 0.058891645988420185\n",
      "en\t gengångare\t 2\t 13514\t 0.0001479946721918011\n",
      "Prob. bigrams: 1.585151589296086e-06\n",
      "Geometric mean prob.: 0.011659777602800642\n",
      "Entropy rate: 6.422315918766036\n",
      "Perplexity: 85.76492914923207\n",
      "wi\t wi+1\t Ci,i+1\t C(i)\t P(wi)\n",
      "det\t var\t 3839\t 21108\t 0.1818741709304529\n",
      "var\t en\t 712\t 12090\t 0.058891645988420185\n",
      "en\t getabock\t 1\t 13514\t 7.399733609590054e-05\n",
      "Prob. bigrams: 7.92575794648043e-07\n",
      "Geometric mean prob.: 0.009254371616200496\n",
      "Entropy rate: 6.75564925209937\n",
      "Perplexity: 108.05703957785992\n",
      "wi\t wi+1\t Ci,i+1\t C(i)\t P(wi)\n",
      "det\t var\t 3839\t 21108\t 0.1818741709304529\n",
      "var\t en\t 712\t 12090\t 0.058891645988420185\n",
      "en\t gåva\t 6\t 13514\t 0.0004439840165754033\n",
      "Prob. bigrams: 4.7554547678882584e-06\n",
      "Geometric mean prob.: 0.016816309237519173\n",
      "Entropy rate: 5.893995085192317\n",
      "Perplexity: 59.466080569503426\n",
      "wi\t wi+1\t Ci,i+1\t C(i)\t P(wi)\n",
      "det\t var\t 3839\t 21108\t 0.1818741709304529\n",
      "var\t en\t 712\t 12090\t 0.058891645988420185\n",
      "en\t glänsande\t 1\t 13514\t 7.399733609590054e-05\n",
      "Prob. bigrams: 7.92575794648043e-07\n",
      "Geometric mean prob.: 0.009254371616200496\n",
      "Entropy rate: 6.75564925209937\n",
      "Perplexity: 108.05703957785992\n",
      "wi\t wi+1\t Ci,i+1\t C(i)\t P(wi)\n",
      "det\t var\t 3839\t 21108\t 0.1818741709304529\n",
      "var\t en\t 712\t 12090\t 0.058891645988420185\n",
      "en\t grann\t 6\t 13514\t 0.0004439840165754033\n",
      "Prob. bigrams: 4.7554547678882584e-06\n",
      "Geometric mean prob.: 0.016816309237519173\n",
      "Entropy rate: 5.893995085192317\n",
      "Perplexity: 59.466080569503426\n",
      "wi\t wi+1\t Ci,i+1\t C(i)\t P(wi)\n",
      "det\t var\t 3839\t 21108\t 0.1818741709304529\n",
      "var\t en\t 712\t 12090\t 0.058891645988420185\n",
      "en\t gränsbo\t 1\t 13514\t 7.399733609590054e-05\n",
      "Prob. bigrams: 7.92575794648043e-07\n",
      "Geometric mean prob.: 0.009254371616200496\n",
      "Entropy rate: 6.75564925209937\n",
      "Perplexity: 108.05703957785992\n",
      "wi\t wi+1\t Ci,i+1\t C(i)\t P(wi)\n",
      "det\t var\t 3839\t 21108\t 0.1818741709304529\n",
      "var\t en\t 712\t 12090\t 0.058891645988420185\n",
      "en\t ganska\t 7\t 13514\t 0.0005179813526713039\n",
      "Prob. bigrams: 5.548030562536302e-06\n",
      "Geometric mean prob.: 0.01770297604159364\n",
      "Entropy rate: 5.819864278080169\n",
      "Perplexity: 56.48767741934873\n",
      "wi\t wi+1\t Ci,i+1\t C(i)\t P(wi)\n",
      "det\t var\t 3839\t 21108\t 0.1818741709304529\n",
      "var\t en\t 712\t 12090\t 0.058891645988420185\n",
      "en\t glädje\t 16\t 13514\t 0.0011839573775344087\n",
      "Prob. bigrams: 1.2681212714368688e-05\n",
      "Geometric mean prob.: 0.023319555205601285\n",
      "Entropy rate: 5.422315918766036\n",
      "Perplexity: 42.88246457461604\n",
      "wi\t wi+1\t Ci,i+1\t C(i)\t P(wi)\n",
      "det\t var\t 3839\t 21108\t 0.1818741709304529\n",
      "var\t en\t 712\t 12090\t 0.058891645988420185\n",
      "en\t gagnlös\t 1\t 13514\t 7.399733609590054e-05\n",
      "Prob. bigrams: 7.92575794648043e-07\n",
      "Geometric mean prob.: 0.009254371616200496\n",
      "Entropy rate: 6.75564925209937\n",
      "Perplexity: 108.05703957785992\n",
      "wi\t wi+1\t Ci,i+1\t C(i)\t P(wi)\n",
      "det\t var\t 3839\t 21108\t 0.1818741709304529\n",
      "var\t en\t 712\t 12090\t 0.058891645988420185\n",
      "en\t godmodig\t 1\t 13514\t 7.399733609590054e-05\n",
      "Prob. bigrams: 7.92575794648043e-07\n",
      "Geometric mean prob.: 0.009254371616200496\n",
      "Entropy rate: 6.75564925209937\n",
      "Perplexity: 108.05703957785992\n",
      "wi\t wi+1\t Ci,i+1\t C(i)\t P(wi)\n",
      "det\t var\t 3839\t 21108\t 0.1818741709304529\n",
      "var\t en\t 712\t 12090\t 0.058891645988420185\n",
      "en\t gård\t 31\t 13514\t 0.002293917418972917\n",
      "Prob. bigrams: 2.4569849634089336e-05\n",
      "Geometric mean prob.: 0.029071503945172304\n",
      "Entropy rate: 5.1042504819704115\n",
      "Perplexity: 34.39794521418502\n",
      "wi\t wi+1\t Ci,i+1\t C(i)\t P(wi)\n",
      "det\t var\t 3839\t 21108\t 0.1818741709304529\n",
      "var\t en\t 712\t 12090\t 0.058891645988420185\n",
      "en\t gosse\t 8\t 13514\t 0.0005919786887672044\n",
      "Prob. bigrams: 6.340606357184344e-06\n",
      "Geometric mean prob.: 0.018508743232400992\n",
      "Entropy rate: 5.75564925209937\n",
      "Perplexity: 54.02851978892996\n",
      "wi\t wi+1\t Ci,i+1\t C(i)\t P(wi)\n",
      "det\t var\t 3839\t 21108\t 0.1818741709304529\n",
      "var\t en\t 712\t 12090\t 0.058891645988420185\n",
      "en\t gast\t 4\t 13514\t 0.0002959893443836022\n",
      "Prob. bigrams: 3.170303178592172e-06\n",
      "Geometric mean prob.: 0.014690399238861314\n",
      "Entropy rate: 6.088982585432703\n",
      "Perplexity: 68.07166937673456\n",
      "wi\t wi+1\t Ci,i+1\t C(i)\t P(wi)\n",
      "det\t var\t 3839\t 21108\t 0.1818741709304529\n",
      "var\t en\t 712\t 12090\t 0.058891645988420185\n",
      "en\t gudsförnekare\t 1\t 13514\t 7.399733609590054e-05\n",
      "Prob. bigrams: 7.92575794648043e-07\n",
      "Geometric mean prob.: 0.009254371616200496\n",
      "Entropy rate: 6.75564925209937\n",
      "Perplexity: 108.05703957785992\n",
      "wi\t wi+1\t Ci,i+1\t C(i)\t P(wi)\n",
      "det\t var\t 3839\t 21108\t 0.1818741709304529\n",
      "var\t en\t 712\t 12090\t 0.058891645988420185\n",
      "en\t glittrande\t 1\t 13514\t 7.399733609590054e-05\n",
      "Prob. bigrams: 7.92575794648043e-07\n",
      "Geometric mean prob.: 0.009254371616200496\n",
      "Entropy rate: 6.75564925209937\n",
      "Perplexity: 108.05703957785992\n",
      "wi\t wi+1\t Ci,i+1\t C(i)\t P(wi)\n",
      "det\t var\t 3839\t 21108\t 0.1818741709304529\n",
      "var\t en\t 712\t 12090\t 0.058891645988420185\n",
      "en\t gråvädersdag\t 1\t 13514\t 7.399733609590054e-05\n",
      "Prob. bigrams: 7.92575794648043e-07\n",
      "Geometric mean prob.: 0.009254371616200496\n",
      "Entropy rate: 6.75564925209937\n",
      "Perplexity: 108.05703957785992\n",
      "{'gång': 12.135327409972229, 'gammal': 18.237499237585666, 'god': 20.247521513415126, 'gård': 34.39794521418502, 'glädje': 42.88246457461604, 'glad': 47.19825942622773, 'gås': 48.58723332824373, 'gosse': 54.02851978892996, 'graf': 56.48767741934873, 'ganska': 56.48767741934873, 'gåva': 59.466080569503426, 'grann': 59.466080569503426, 'grov': 63.192140092886426, 'gast': 68.07166937673456, 'gammaldags': 74.9225666642619, 'gruva': 85.76492914923207, 'gengångare': 85.76492914923207, 'gruvarbetare': 108.05703957785992, 'getabock': 108.05703957785992, 'glänsande': 108.05703957785992, 'gränsbo': 108.05703957785992, 'gagnlös': 108.05703957785992, 'godmodig': 108.05703957785992, 'gudsförnekare': 108.05703957785992, 'glittrande': 108.05703957785992, 'gråvädersdag': 108.05703957785992}\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenize(current_text)\n",
    "candidates = []\n",
    "for k, v in frequency_trigrams.items():\n",
    "    if list(k[0:2]) == tokens[1:3] and k[2].startswith(tokens[3]):\n",
    "        candidates.append((k[2], bigram_lm(frequency, frequency_bigrams, tokens[:-1] + [k[2]])))\n",
    "        \n",
    "        \n",
    "merged_candidates = {}\n",
    "for k, f in candidates:\n",
    "    merged_candidates[k] = f\n",
    "    \n",
    "sorted_candidates = {k: v for k, v in sorted(merged_candidates.items(), key=lambda item: item[1])}\n",
    "print(sorted_candidates)\n",
    "current_word_predictions_2 = []\n",
    "for i, k in enumerate(sorted_candidates.keys()):\n",
    "    if i == cand_nbr:\n",
    "        break\n",
    "    current_word_predictions_2.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gång', 'gammal', 'god', 'gård', 'glädje']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_word_predictions_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checked answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The system will check these answers: `(perplexity_unigrams, perplexity_bigrams, current_word_predictions_1, next_word_predictions, current_word_predictions_2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(423,\n",
       " 72,\n",
       " ['det', 'de', 'den', 'dem', 'detta'],\n",
       " ['stor', 'liten', 'gammal', 'god', 'sådan'],\n",
       " ['gång', 'gammal', 'god', 'gård', 'glädje'])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(perplexity_unigrams, perplexity_bigrams, current_word_predictions_1, next_word_predictions, current_word_predictions_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you have written all the code and run all the cells, fill in your ID and as well as the name of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "STIL_ID = [\"ol7501en-s\"] # Write your stil ids as a list\n",
    "CURRENT_NOTEBOOK_PATH = os.path.join(os.getcwd(), \n",
    "                                     \"2-language_models.ipynb\") # Write the name of your notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The submission code will send your answer. It consists of the perplexities and predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"(423, 72, ['det', 'de', 'den', 'dem', 'detta'], ['stor', 'liten', 'gammal', 'god', 'sådan'], ['gång', 'gammal', 'god', 'gård', 'glädje'])\""
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANSWER = str((perplexity_unigrams, perplexity_bigrams, current_word_predictions_1, next_word_predictions, current_word_predictions_2))\n",
    "ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the moment of truth:\n",
    "1. Save your notebook and\n",
    "2. Run the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBMISSION_NOTEBOOK_PATH = CURRENT_NOTEBOOK_PATH + \".submission.bz2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSIGNMENT = 2\n",
    "API_KEY = \"f581ba347babfea0b8f2c74a3a6776a7\"\n",
    "\n",
    "# Copy and compress current notebook\n",
    "with bz2.open(SUBMISSION_NOTEBOOK_PATH, mode=\"wb\") as fout:\n",
    "    with open(CURRENT_NOTEBOOK_PATH, \"rb\") as fin:\n",
    "        fout.write(fin.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'msg': None,\n",
       " 'status': 'incorrect',\n",
       " 'signature': None,\n",
       " 'submission_id': 'fad61192-4634-467d-94d9-61ea8d252acc'}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = requests.post(\"https://vilde.cs.lth.se/edan20checker/submit\", \n",
    "                    files={\"notebook_file\": open(SUBMISSION_NOTEBOOK_PATH, \"rb\")}, \n",
    "                    data={\n",
    "                        \"stil_id\": STIL_ID,\n",
    "                        \"assignment\": ASSIGNMENT,\n",
    "                        \"answer\": ANSWER,\n",
    "                        \"api_key\": API_KEY,\n",
    "                    },\n",
    "                   verify=True)\n",
    "\n",
    "# from IPython.display import display, JSON\n",
    "res.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>As an application of n-grams, execute the Jupyter notebook by Peter Norvig <a\n",
    "        href=\"http://nbviewer.jupyter.org/url/norvig.com/ipython/How%20to%20Do%20Things%20with%20Words.ipynb\">\n",
    "    here</a>. Just run all the cells and be sure that you understand the code.\n",
    "    You will find the data <a href=\"http://norvig.com/ngrams/\">here</a>.</p>\n",
    "<p>In your report, you will also describe one experiment with a long string of words\n",
    "    your will create yourself or copy from a text you like. You will remove all the punctuation and\n",
    "    white spaces from this string. Set this string in lowercase letters.</p>\n",
    "<p>You will just add a cell at the end of Sect. 7 in Norvig's notebook, where you will use your string and\n",
    "    run the notebook cell with the <tt>segment()</tt> and <tt>segment2()</tt> functions. </p>\n",
    "<p>You will comment the segmentation results you obtain with unigram and bigram models.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
